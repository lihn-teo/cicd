‰Ω†ÊòØÊÉ≥Áî® LocalStack Êù•Ê®°Êãü AWS ÁéØÂ¢ÉÔºåÂú®Êú¨Âú∞Áî® AWS CDK ÈÉ®ÁΩ≤Ôºå‰∏ä‰º†Êñá‰ª∂Âà∞ S3ÔºåÁÑ∂ÂêéÁî® Pipeline (CodePipeline) Êù•ÂÅöÂ§ÑÁêÜÔºåÂØπÂêßÔºü

ÊàëÂ∏Æ‰Ω†Ê¢≥ÁêÜ‰∏Ä‰∏ãÊÄùË∑ØÔºö

1. ÁéØÂ¢ÉÂáÜÂ§á

ÂÆâË£Ö LocalStack

pip install localstack


ÊàñËÄÖÁî® Docker ÂêØÂä®Ôºö

docker run --rm -it -p 4566:4566 -p 4510-4559:4510-4559 localstack/localstack


ÂÆâË£Ö CDK v2

npm install -g aws-cdk
pip install aws-cdk-lib constructs


ÈÖçÁΩÆ AWS CLI ÊåáÂêë LocalStack

aws configure


Access/Secret ÂèØ‰ª•Èöè‰æøÂ°´ÔºåÊØîÂ¶ÇÔºö

AWS Access Key ID [None]: test
AWS Secret Access Key [None]: test
Default region name [None]: us-east-1
Default output format [None]: json


ÁÑ∂ÂêéÂú® shell ÈáåÊåáÂÆö LocalStack ÁöÑ endpointÔºö

export AWS_ACCESS_KEY_ID=test
export AWS_SECRET_ACCESS_KEY=test
export AWS_DEFAULT_REGION=us-east-1
export LOCALSTACK_HOST=localhost
export EDGE_PORT=4566

2. Áî® CDK ÂÆö‰πâ S3 + Pipeline

CDK v2 Python ‰æãÂ≠êÔºàÈÉ®ÁΩ≤Âà∞ LocalStack ÁöÑÊó∂ÂÄô‰ºöÂèòÊàê‚ÄúÊú¨Âú∞ÁöÑ S3 Âíå Pipeline‚ÄùÔºâÔºö

my_stack.py
from aws_cdk import (
    Stack,
    aws_s3 as s3,
    aws_codepipeline as codepipeline,
    aws_codepipeline_actions as cpactions,
)
from constructs import Construct

class MyStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # S3 bucket (source)
        source_bucket = s3.Bucket(self, "MySourceBucket")

        # S3 bucket (artifact store for pipeline)
        artifact_bucket = s3.Bucket(self, "PipelineArtifacts")

        # CodePipeline
        pipeline = codepipeline.Pipeline(
            self, "MyPipeline",
            artifact_bucket=artifact_bucket
        )

        # Artifact ÂÆö‰πâ
        source_output = codepipeline.Artifact()

        # Source stage (S3 ‚Üí Pipeline)
        pipeline.add_stage(
            stage_name="Source",
            actions=[
                cpactions.S3SourceAction(
                    action_name="S3Source",
                    bucket=source_bucket,
                    bucket_key="input.zip",
                    output=source_output
                )
            ]
        )

        # Build/Processing stage (Á§∫‰æãÔºåËøôÈáåÂè™ÊòØ PassThrough)
        pipeline.add_stage(
            stage_name="Build",
            actions=[
                cpactions.ManualApprovalAction(
                    action_name="Approve"
                )
            ]
        )

app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyStack

app = cdk.App()
MyStack(app, "MyStack")
app.synth()

3. ÈÉ®ÁΩ≤Âà∞ LocalStack

ÈÉ®ÁΩ≤Êó∂Ë¶ÅÂëäËØâ CDK ‰ΩøÁî® LocalStack endpointÔºö

cdk deploy --profile default \
  --require-approval never \
  --context localstack=true \
  --outputs-file cdk-outputs.json


ÊàñËÄÖÁî® cdklocal
ÔºàÊé®ËçêÔºâÔºö

pip install aws-cdk-local
cdklocal deploy

4. ÊµãËØï‰∏ä‰º†Êñá‰ª∂

Êää input.zip ‰∏ä‰º†Âà∞ LocalStack ÁöÑ S3 bucketÔºö

aws --endpoint-url=http://localhost:4566 s3 cp ./input.zip s3://my-source-bucket/input.zip


ÁÑ∂ÂêéÂèØ‰ª•Êü•Áúã LocalStack ÈáåÁöÑ Pipeline ÊòØÂê¶Ëß¶ÂèëÔºö

aws --endpoint-url=http://localhost:4566 codepipeline list-pipelines
aws --endpoint-url=http://localhost:4566 codepipeline get-pipeline-state --name MyPipeline


‚ö†Ô∏è Ê≥®ÊÑèÔºöLocalStack ÂØπ CodePipeline ÁöÑÊîØÊåÅËøò‰∏çÂÆåÂÖ®ÔºåÊúâ‰∫õ ActionÔºàÊØîÂ¶Ç CodeBuild„ÄÅCodeDeployÔºâÂèØËÉΩÈúÄË¶Å Pro ÁâàÊâçË°å„ÄÇ
ÊâÄ‰ª•Â¶ÇÊûú‰Ω†Âè™ÊòØÂÅöÊú¨Âú∞È™åËØÅÔºåS3 + Pipeline ÁöÑ‚ÄúÊµÅËΩ¨‚ÄùÂèØ‰ª•Ë∑ëÔºå‰ΩÜÁúüÊ≠£ÁöÑ Build Èò∂ÊÆµÂèØËÉΩÂè™ËÉΩÁî® ManualApprovalAction ÊàñËÄÖËá™Â∑±Ê®°Êãü„ÄÇ

Ë¶Å‰∏çË¶ÅÊàëÂ∏Æ‰Ω†ÂÜô‰∏Ä‰∏™ ÊúÄÁÆÄ LocalStack CDK Á§∫‰æãÔºàÂè™ÂåÖÂê´ S3 + PipelineÔºåËÉΩÂú®‰Ω†Êú¨Âú∞Ë∑ëÈÄöÔºâÔºå‰Ω†Áõ¥Êé•Â§çÂà∂ÊâßË°åÂ∞±ËÉΩÁúãÂà∞ÊïàÊûúÔºü

„ÅÇ„Å™„Åü:
vpcÔºå ECSÔºå RDS for Aurora ÂÅöÊàêËøôÊ†∑ÁöÑÁéØÂ¢É
ChatGPT:

ÊòéÁôΩ‰∫Ü üëç
‰Ω†ÊÉ≥Âú® LocalStack + AWS CDK v2 (Python) ÈáåÔºåÂÆö‰πâ‰∏Ä‰∏™ VPC + ECS (Fargate) + RDS (Aurora) ÁöÑÁéØÂ¢ÉÔºåÂØπÂêßÔºü

ÊàëÂÖàËØ¥Êòé‰∏Ä‰∏ãÔºö

LocalStack Á§æÂå∫Áâà (ÂÖçË¥πÁâà)Ôºö

S3, SQS, SNS, DynamoDB, Lambda, API Gateway Á≠âÊîØÊåÅÂæàÂ•Ω

‰ΩÜÊòØ VPC / ECS / RDS / Aurora Á≠âÁΩëÁªúÁ±ªÂíåÊï∞ÊçÆÂ∫ìÁ±ªÊúçÂä°ÊîØÊåÅÊúâÈôêÔºåÂ§ßÂ§öÊï∞ÈúÄË¶Å LocalStack Pro ÊàñËÄÖ Êó†Ê≥ïÂÆåÊï¥Ê®°Êãü

‰πüÂ∞±ÊòØËØ¥Ôºö

VPC/CDK ‰ºöÂêàÊàêÔºå‰ΩÜ‰∏ç‰ºöÁúüÁöÑÂàõÂª∫Â≠êÁΩë„ÄÅÂÆâÂÖ®ÁªÑ

ECS/Fargate ‰ºöÂêàÊàêÔºå‰ΩÜ‰ªªÂä°‰∏ç‰ºöÁúüÁöÑË∑ë

Aurora ‰πü‰∏ç‰ºöÁúüÁöÑË∑ëÊï∞ÊçÆÂ∫ìÂºïÊìéÔºåÂè™ËÉΩ mock endpoint

üëâ Â¶ÇÊûú‰Ω†Âè™ÊòØÈúÄË¶Å ÁªÉ‰π† CDK IaC ÁºñÁ†ÅÔºàËÄå‰∏çÊòØË∑ëÁúüÁöÑÂÆπÂô®/Êï∞ÊçÆÂ∫ìÔºâÔºåÂÆåÂÖ®ÂèØ‰ª•Âú® LocalStack ÈáåÈÉ®ÁΩ≤Ôºå‰ºöÁîüÊàêÁõ∏Â∫îÁöÑËµÑÊ∫ê stub„ÄÇ
üëâ Â¶ÇÊûú‰Ω†ÈúÄË¶ÅÁúüÁöÑËøêË°å ECS ‰ªªÂä°ÊàñËÄÖËøû‰∏ä Aurora Êï∞ÊçÆÂ∫ìÔºåÂ∞±ÂøÖÈ°ªÁî® AWS ÁúüÁéØÂ¢É Êàñ LocalStack Pro„ÄÇ

üìå CDK v2 ‰ª£Á†ÅÁ§∫‰æãÔºàVPC + ECS + AuroraÔºâ

‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ ÊúÄÂ∞èÂèØËøêË°å CDK v2 Ê†∑‰æãÔºåÂú®ÁúüÂÆû AWS ‰∏äËÉΩÂàõÂª∫ÂÆåÊï¥ÁéØÂ¢ÉÔºåÂú® LocalStack ‰∏äËÉΩÂêàÊàê+ÈÉ®ÂàÜ stubÔºö

app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyInfraStack

app = cdk.App()
MyInfraStack(app, "MyInfraStack")
app.synth()

my_stack.py
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # Fargate Service with Load Balancer (Hello World container)
        ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # RDS Aurora (Serverless v2)
        rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

üöÄ ÈÉ®ÁΩ≤ÊñπÊ≥ï
1. LocalStackÔºàmock ËµÑÊ∫êÔºâ
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never

2. AWS ÁúüÁéØÂ¢É
cdk bootstrap
cdk deploy --require-approval never

‚úÖ ÁªìÊûú

Âú® AWS ÁúüÁéØÂ¢ÉÔºö

ÂàõÂª∫‰∏Ä‰∏™ VPCÔºà2 AZÔºâ

ÈÉ®ÁΩ≤‰∏Ä‰∏™ ECS Fargate Cluster + ALB + Sample Container

ÂàõÂª∫‰∏Ä‰∏™ Aurora MySQL ClusterÔºàserverlessÔºâ

Âú® LocalStackÔºö

ËµÑÊ∫ê‰ºö‚ÄúÂêàÊàê‚ÄùÂá∫Êù•Ôºå‰ΩÜ ECS ‰ªªÂä°Âíå Aurora Êï∞ÊçÆÂ∫ì‰∏ç‰ºöÁúüÁöÑË∑ëÔºåÂè™ËÉΩ‰Ωú‰∏∫ IaC ÊµãËØï

Ë¶Å‰∏çË¶ÅÊàëÂ∏Æ‰Ω†ÂÅö‰∏Ä‰∏™ ÁÆÄÂåñÁâàÊú¨ÔºåÂè™Áî® VPC + ECSÔºà‰∏çÂä† AuroraÔºâÔºåËøôÊ†∑‰Ω†ËÉΩÂú® LocalStack ÂÖçË¥πÁâàÈáåË∑ëÈÄöÔºåÂπ∂ÁúãÂà∞ ECS cluster stubÔºü

„ÅÇ„Å™„Åü:
ÂÅö‰∏Ä‰∏™ÂÆåÊï¥ÁöÑpythonÂ∑•Á®ãÔºåÂÆûÁé∞‰∏äÈù¢ÁöÑÂÜÖÂÆπ
ChatGPT:

ÊòéÁôΩ‰∫ÜÔºåÊàëÂ∏Æ‰Ω†Êï¥ÁêÜ‰∏Ä‰∏™ ÂÆåÊï¥ÁöÑ Python CDK v2 Â∑•Á®ãÁªìÊûÑÔºåÂÆûÁé∞ VPC + ECS (Fargate) + Aurora MySQL„ÄÇËøô‰∏™Â∑•Á®ãÂú® AWS ÁúüÁéØÂ¢ÉÂèØ‰ª•ÂÆåÂÖ®ÈÉ®ÁΩ≤ÔºåÂú® LocalStack ÂÖçË¥πÁâàÂè™ËÉΩÊ®°ÊãüÈÉ®ÂàÜËµÑÊ∫êÔºàECS/Aurora ‰ªªÂä°‰∏ç‰ºöÁúüÊ≠£ËøêË°åÔºâ„ÄÇ

1Ô∏è‚É£ Â∑•Á®ãÁªìÊûÑ
my_cdk_project/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ my_stack.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ cdk.json
‚îî‚îÄ‚îÄ README.md

2Ô∏è‚É£ requirements.txt
aws-cdk-lib>=2.0.0
constructs>=10.0.0


Â¶ÇÊûúÁî® LocalStackÔºö

aws-cdk-lib>=2.0.0
constructs>=10.0.0
aws-cdk-local


ÂÆâË£Ö‰æùËµñÔºö

python -m pip install -r requirements.txt

3Ô∏è‚É£ cdk.json
{
  "app": "python3 app.py"
}

4Ô∏è‚É£ app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyInfraStack

app = cdk.App()
MyInfraStack(app, "MyInfraStack")
app.synth()

5Ô∏è‚É£ my_stack.py
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # 1. ÂàõÂª∫ VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # 2. ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # 3. Fargate Service + ALB
        ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # 4. Aurora MySQL Cluster (Serverless)
        rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

6Ô∏è‚É£ ÈÉ®ÁΩ≤Ê≠•È™§
‚úÖ AWS ÁúüÁéØÂ¢É
cdk bootstrap
cdk deploy --require-approval never

‚úÖ LocalStackÔºàÊ®°ÊãüËµÑÊ∫êÔºâ
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never


‰∏ä‰º† ECS ÈïúÂÉèÊàñËÄÖÊµãËØï S3 ÂèØÈÄöËøá LocalStack endpointÔºö

aws --endpoint-url=http://localhost:4566 s3 cp ./input.zip s3://my-bucket/

7Ô∏è‚É£ Ê≥®ÊÑè‰∫ãÈ°π

LocalStack ÂÖçË¥πÁâà‰∏çËÉΩÁúüÊ≠£ËøêË°å ECS ‰ªªÂä°Êàñ AuroraÔºåÂè™ËÉΩÂÅö IaC ÊµãËØï„ÄÇ

Aurora Serverless v2 ÈúÄË¶ÅÁúüÂÆû AWS ÊâçËÉΩÂêØÂä®Êï∞ÊçÆÂ∫ì„ÄÇ

ECS Fargate Task ÈúÄË¶ÅÂÖ¨ÂºÄÈïúÂÉèÔºàÂ¶Ç amazon/amazon-ecs-sampleÔºâÊâçËÉΩÂú® AWS ‰∏äËøêË°å„ÄÇ

ÂèØ‰ª•Âú® LocalStack ÊµãËØï CDK synth ÂíåËµÑÊ∫êÁîüÊàêÈÄªËæë„ÄÇ

ÊàëÂèØ‰ª•Â∏Æ‰Ω†Ëøõ‰∏ÄÊ≠•ÂÅö‰∏Ä‰∏™ ÈôÑÂä†ÂäüËÉΩÔºö

Ëá™Âä®‰∏ä‰º†Êñá‰ª∂Âà∞ S3

Ëß¶Âèë ECS ‰ªªÂä°Â§ÑÁêÜ

ËæìÂá∫ Aurora endpoint

ËøôÊ†∑Â∞±ÊòØ‰∏Ä‰∏™ ÂÆåÊï¥ÂèØÊâßË°åÁöÑ‚ÄúÊú¨Âú∞/‰∫ë‚ÄùÊ®°Êãü + ÁúüÁéØÂ¢ÉÈÉ®ÁΩ≤Â∑•Á®ã„ÄÇ

‰Ω†Â∏åÊúõÊàëÂä†Ëøô‰∏™ÂêóÔºü

„ÅÇ„Å™„Åü:
Â∏åÊúõ
ChatGPT:

ÊòéÁôΩ‰∫ÜÔºåÊàëÁªô‰Ω†Êâ©Â±ïËøô‰∏™Â∑•Á®ãÔºåËÆ©ÂÆÉÊîØÊåÅÔºö

‰∏ä‰º†Êñá‰ª∂Âà∞ S3

Ëß¶Âèë ECS ‰ªªÂä°Â§ÑÁêÜÔºàÊ®°ÊãüÂ§ÑÁêÜÔºâ

ËæìÂá∫ Aurora endpoint

‰∏ãÈù¢ÊòØÂÆåÊï¥ÊñπÊ°àÔºå‰øùÊåÅ CDK v2 PythonÔºåÂèØÂú® AWS ÁúüÁéØÂ¢ÉÈÉ®ÁΩ≤ÔºåLocalStack ÂèØÊ®°Êãü IaC ÊµÅÁ®ã„ÄÇ

1Ô∏è‚É£ Â∑•Á®ãÁªìÊûÑÔºàÊõ¥Êñ∞Ôºâ
my_cdk_project/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ my_stack.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ upload_file.py
‚îú‚îÄ‚îÄ cdk.json
‚îî‚îÄ‚îÄ README.md

2Ô∏è‚É£ requirements.txtÔºàÊõ¥Êñ∞Ôºâ
aws-cdk-lib>=2.0.0
constructs>=10.0.0
boto3>=1.26.0
aws-cdk-local  # Â¶ÇÊûúÁî® LocalStack


ÂÆâË£ÖÔºö

python -m pip install -r requirements.txt

3Ô∏è‚É£ my_stack.pyÔºàCDK Ê†∏ÂøÉ + S3 + ECS + Aurora + ËæìÂá∫Ôºâ
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_s3 as s3,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
    CfnOutput,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # 1Ô∏è‚É£ VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # 2Ô∏è‚É£ S3 BucketÔºà‰∏ä‰º†Êñá‰ª∂Áî®Ôºâ
        source_bucket = s3.Bucket(self, "MySourceBucket")

        # 3Ô∏è‚É£ ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # 4Ô∏è‚É£ Fargate Service + ALB
        fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # 5Ô∏è‚É£ Aurora MySQL Cluster (Serverless)
        aurora_cluster = rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

        # 6Ô∏è‚É£ ËæìÂá∫‰ø°ÊÅØ
        CfnOutput(self, "S3BucketName", value=source_bucket.bucket_name)
        CfnOutput(self, "FargateURL", value=fargate_service.load_balancer.load_balancer_dns_name)
        CfnOutput(self, "AuroraEndpoint", value=aurora_cluster.cluster_endpoint.hostname)

4Ô∏è‚É£ scripts/upload_file.pyÔºà‰∏ä‰º†Êñá‰ª∂Âà∞ S3 + Ê®°ÊãüËß¶Âèë ECSÔºâ
import boto3
import os

# AWS ÈÖçÁΩÆ
AWS_REGION = "us-east-1"
S3_BUCKET = os.environ.get("S3_BUCKET", "MySourceBucket")  # ÂèØ‰ªé CDK ËæìÂá∫‰º†ÂÖ•
FILE_PATH = "input.zip"
KEY_NAME = "input.zip"

# 1Ô∏è‚É£ ‰∏ä‰º†Êñá‰ª∂Âà∞ S3
s3_client = boto3.client("s3", region_name=AWS_REGION)
s3_client.upload_file(FILE_PATH, S3_BUCKET, KEY_NAME)
print(f"Uploaded {FILE_PATH} to s3://{S3_BUCKET}/{KEY_NAME}")

# 2Ô∏è‚É£ Ê®°ÊãüËß¶Âèë ECS ‰ªªÂä°
ecs_client = boto3.client("ecs", region_name=AWS_REGION)
cluster_name = os.environ.get("ECS_CLUSTER", "MyCluster")
task_definition = os.environ.get("TASK_DEF", "MyFargateService")  # CDK ‰ºöËá™Âä®ÂàõÂª∫

response = ecs_client.run_task(
    cluster=cluster_name,
    launchType="FARGATE",
    taskDefinition=task_definition,
    networkConfiguration={
        'awsvpcConfiguration': {
            'subnets': ['subnet-xxxxxx'],  # ÊõøÊç¢Êàê CDK ËæìÂá∫ÁöÑÁßÅÊúâÂ≠êÁΩë
            'assignPublicIp': 'ENABLED'
        }
    }
)
print("ECS task triggered:", response)


‚ö†Ô∏è Ê≥®ÊÑèÔºö

Âú® AWS ‰∏äÔºåsubnets ÂøÖÈ°ªÊõøÊç¢‰∏∫ CDK ËæìÂá∫ÁöÑ VPC Â≠êÁΩë ID„ÄÇ

LocalStack ÂÖçË¥πÁâàÊó†Ê≥ïÁúüÊ≠£ËøêË°å ECS ‰ªªÂä°Ôºå‰ΩÜ‰Ω†ÂèØ‰ª•ÊµãËØï IaC ÊµÅÁ®ãÂíå S3 ‰∏ä‰º†„ÄÇ

5Ô∏è‚É£ ÈÉ®ÁΩ≤ & ÊµãËØï
AWS ÁúüÁéØÂ¢ÉÔºö
cdk bootstrap
cdk deploy --require-approval never


Êü•ÁúãËæìÂá∫Ôºö

aws s3 ls
# ËæìÂá∫ S3 bucket ÂêçÁß∞


‰∏ä‰º†Êñá‰ª∂Âπ∂Ëß¶Âèë ECSÔºö

export S3_BUCKET=<CDKËæìÂá∫ÁöÑS3BucketName>
export ECS_CLUSTER=<CDKËæìÂá∫ÁöÑClusterName>
export TASK_DEF=<CDKËæìÂá∫ÁöÑFargateServiceName>
python scripts/upload_file.py

LocalStack Ê®°ÊãüÔºö
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never

export AWS_ACCESS_KEY_ID=test
export AWS_SECRET_ACCESS_KEY=test
export AWS_DEFAULT_REGION=us-east-1
export S3_BUCKET=MySourceBucket
python scripts/upload_file.py --endpoint-url=http://localhost:4566


LocalStack ÂÖçË¥πÁâàÔºö

S3 ‰∏ä‰º†‰ºöÊàêÂäü

ECS ‰ªªÂä°Âíå Aurora endpoint Âè™ÊòØ mockÔºå‰∏ç‰ºöÁúüÊ≠£ËøêË°å

ÊàëÂèØ‰ª•Â∏Æ‰Ω†ÂÜçÂÜô‰∏Ä‰∏™ ËÑöÊú¨Ëá™Âä®ËØªÂèñ CDK ËæìÂá∫ÔºåÂπ∂Âä®ÊÄÅÂ°´ÂÖÖ ECS Â≠êÁΩë/Task DefinitionÔºåËøôÊ†∑ upload_file.py ÂèØ‰ª• Áõ¥Êé•Êãø CDK ËæìÂá∫ËøêË°åÔºå‰∏çÈúÄË¶ÅÊâãÂä®ÊõøÊç¢„ÄÇ

‰Ω†Â∏åÊúõÊàëÂä†ÂêóÔºü

