ä½ æ˜¯æƒ³ç”¨ LocalStack æ¥æ¨¡æ‹Ÿ AWS ç¯å¢ƒï¼Œåœ¨æœ¬åœ°ç”¨ AWS CDK éƒ¨ç½²ï¼Œä¸Šä¼ æ–‡ä»¶åˆ° S3ï¼Œç„¶åç”¨ Pipeline (CodePipeline) æ¥åšå¤„ç†ï¼Œå¯¹å§ï¼Ÿ

æˆ‘å¸®ä½ æ¢³ç†ä¸€ä¸‹æ€è·¯ï¼š

1. ç¯å¢ƒå‡†å¤‡

å®‰è£… LocalStack

pip install localstack


æˆ–è€…ç”¨ Docker å¯åŠ¨ï¼š

docker run --rm -it -p 4566:4566 -p 4510-4559:4510-4559 localstack/localstack


å®‰è£… CDK v2

npm install -g aws-cdk
pip install aws-cdk-lib constructs


é…ç½® AWS CLI æŒ‡å‘ LocalStack

aws configure


Access/Secret å¯ä»¥éšä¾¿å¡«ï¼Œæ¯”å¦‚ï¼š

AWS Access Key ID [None]: test
AWS Secret Access Key [None]: test
Default region name [None]: us-east-1
Default output format [None]: json


ç„¶ååœ¨ shell é‡ŒæŒ‡å®š LocalStack çš„ endpointï¼š

export AWS_ACCESS_KEY_ID=test
export AWS_SECRET_ACCESS_KEY=test
export AWS_DEFAULT_REGION=us-east-1
export LOCALSTACK_HOST=localhost
export EDGE_PORT=4566

2. ç”¨ CDK å®šä¹‰ S3 + Pipeline

CDK v2 Python ä¾‹å­ï¼ˆéƒ¨ç½²åˆ° LocalStack çš„æ—¶å€™ä¼šå˜æˆâ€œæœ¬åœ°çš„ S3 å’Œ Pipelineâ€ï¼‰ï¼š

my_stack.py
from aws_cdk import (
    Stack,
    aws_s3 as s3,
    aws_codepipeline as codepipeline,
    aws_codepipeline_actions as cpactions,
)
from constructs import Construct

class MyStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # S3 bucket (source)
        source_bucket = s3.Bucket(self, "MySourceBucket")

        # S3 bucket (artifact store for pipeline)
        artifact_bucket = s3.Bucket(self, "PipelineArtifacts")

        # CodePipeline
        pipeline = codepipeline.Pipeline(
            self, "MyPipeline",
            artifact_bucket=artifact_bucket
        )

        # Artifact å®šä¹‰
        source_output = codepipeline.Artifact()

        # Source stage (S3 â†’ Pipeline)
        pipeline.add_stage(
            stage_name="Source",
            actions=[
                cpactions.S3SourceAction(
                    action_name="S3Source",
                    bucket=source_bucket,
                    bucket_key="input.zip",
                    output=source_output
                )
            ]
        )

        # Build/Processing stage (ç¤ºä¾‹ï¼Œè¿™é‡Œåªæ˜¯ PassThrough)
        pipeline.add_stage(
            stage_name="Build",
            actions=[
                cpactions.ManualApprovalAction(
                    action_name="Approve"
                )
            ]
        )

app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyStack

app = cdk.App()
MyStack(app, "MyStack")
app.synth()

3. éƒ¨ç½²åˆ° LocalStack

éƒ¨ç½²æ—¶è¦å‘Šè¯‰ CDK ä½¿ç”¨ LocalStack endpointï¼š

cdk deploy --profile default \
  --require-approval never \
  --context localstack=true \
  --outputs-file cdk-outputs.json


æˆ–è€…ç”¨ cdklocal
ï¼ˆæ¨èï¼‰ï¼š

pip install aws-cdk-local
cdklocal deploy

4. æµ‹è¯•ä¸Šä¼ æ–‡ä»¶

æŠŠ input.zip ä¸Šä¼ åˆ° LocalStack çš„ S3 bucketï¼š

aws --endpoint-url=http://localhost:4566 s3 cp ./input.zip s3://my-source-bucket/input.zip


ç„¶åå¯ä»¥æŸ¥çœ‹ LocalStack é‡Œçš„ Pipeline æ˜¯å¦è§¦å‘ï¼š

aws --endpoint-url=http://localhost:4566 codepipeline list-pipelines
aws --endpoint-url=http://localhost:4566 codepipeline get-pipeline-state --name MyPipeline


âš ï¸ æ³¨æ„ï¼šLocalStack å¯¹ CodePipeline çš„æ”¯æŒè¿˜ä¸å®Œå…¨ï¼Œæœ‰äº› Actionï¼ˆæ¯”å¦‚ CodeBuildã€CodeDeployï¼‰å¯èƒ½éœ€è¦ Pro ç‰ˆæ‰è¡Œã€‚
æ‰€ä»¥å¦‚æœä½ åªæ˜¯åšæœ¬åœ°éªŒè¯ï¼ŒS3 + Pipeline çš„â€œæµè½¬â€å¯ä»¥è·‘ï¼Œä½†çœŸæ­£çš„ Build é˜¶æ®µå¯èƒ½åªèƒ½ç”¨ ManualApprovalAction æˆ–è€…è‡ªå·±æ¨¡æ‹Ÿã€‚

è¦ä¸è¦æˆ‘å¸®ä½ å†™ä¸€ä¸ª æœ€ç®€ LocalStack CDK ç¤ºä¾‹ï¼ˆåªåŒ…å« S3 + Pipelineï¼Œèƒ½åœ¨ä½ æœ¬åœ°è·‘é€šï¼‰ï¼Œä½ ç›´æ¥å¤åˆ¶æ‰§è¡Œå°±èƒ½çœ‹åˆ°æ•ˆæœï¼Ÿ

ã‚ãªãŸ:
vpcï¼Œ ECSï¼Œ RDS for Aurora åšæˆè¿™æ ·çš„ç¯å¢ƒ
ChatGPT:

æ˜ç™½äº† ğŸ‘
ä½ æƒ³åœ¨ LocalStack + AWS CDK v2 (Python) é‡Œï¼Œå®šä¹‰ä¸€ä¸ª VPC + ECS (Fargate) + RDS (Aurora) çš„ç¯å¢ƒï¼Œå¯¹å§ï¼Ÿ

æˆ‘å…ˆè¯´æ˜ä¸€ä¸‹ï¼š

LocalStack ç¤¾åŒºç‰ˆ (å…è´¹ç‰ˆ)ï¼š

S3, SQS, SNS, DynamoDB, Lambda, API Gateway ç­‰æ”¯æŒå¾ˆå¥½

ä½†æ˜¯ VPC / ECS / RDS / Aurora ç­‰ç½‘ç»œç±»å’Œæ•°æ®åº“ç±»æœåŠ¡æ”¯æŒæœ‰é™ï¼Œå¤§å¤šæ•°éœ€è¦ LocalStack Pro æˆ–è€… æ— æ³•å®Œæ•´æ¨¡æ‹Ÿ

ä¹Ÿå°±æ˜¯è¯´ï¼š

VPC/CDK ä¼šåˆæˆï¼Œä½†ä¸ä¼šçœŸçš„åˆ›å»ºå­ç½‘ã€å®‰å…¨ç»„

ECS/Fargate ä¼šåˆæˆï¼Œä½†ä»»åŠ¡ä¸ä¼šçœŸçš„è·‘

Aurora ä¹Ÿä¸ä¼šçœŸçš„è·‘æ•°æ®åº“å¼•æ“ï¼Œåªèƒ½ mock endpoint

ğŸ‘‰ å¦‚æœä½ åªæ˜¯éœ€è¦ ç»ƒä¹  CDK IaC ç¼–ç ï¼ˆè€Œä¸æ˜¯è·‘çœŸçš„å®¹å™¨/æ•°æ®åº“ï¼‰ï¼Œå®Œå…¨å¯ä»¥åœ¨ LocalStack é‡Œéƒ¨ç½²ï¼Œä¼šç”Ÿæˆç›¸åº”çš„èµ„æº stubã€‚
ğŸ‘‰ å¦‚æœä½ éœ€è¦çœŸçš„è¿è¡Œ ECS ä»»åŠ¡æˆ–è€…è¿ä¸Š Aurora æ•°æ®åº“ï¼Œå°±å¿…é¡»ç”¨ AWS çœŸç¯å¢ƒ æˆ– LocalStack Proã€‚

ğŸ“Œ CDK v2 ä»£ç ç¤ºä¾‹ï¼ˆVPC + ECS + Auroraï¼‰

ä¸‹é¢æ˜¯ä¸€ä¸ª æœ€å°å¯è¿è¡Œ CDK v2 æ ·ä¾‹ï¼Œåœ¨çœŸå® AWS ä¸Šèƒ½åˆ›å»ºå®Œæ•´ç¯å¢ƒï¼Œåœ¨ LocalStack ä¸Šèƒ½åˆæˆ+éƒ¨åˆ† stubï¼š

app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyInfraStack

app = cdk.App()
MyInfraStack(app, "MyInfraStack")
app.synth()

my_stack.py
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # Fargate Service with Load Balancer (Hello World container)
        ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # RDS Aurora (Serverless v2)
        rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

ğŸš€ éƒ¨ç½²æ–¹æ³•
1. LocalStackï¼ˆmock èµ„æºï¼‰
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never

2. AWS çœŸç¯å¢ƒ
cdk bootstrap
cdk deploy --require-approval never

âœ… ç»“æœ

åœ¨ AWS çœŸç¯å¢ƒï¼š

åˆ›å»ºä¸€ä¸ª VPCï¼ˆ2 AZï¼‰

éƒ¨ç½²ä¸€ä¸ª ECS Fargate Cluster + ALB + Sample Container

åˆ›å»ºä¸€ä¸ª Aurora MySQL Clusterï¼ˆserverlessï¼‰

åœ¨ LocalStackï¼š

èµ„æºä¼šâ€œåˆæˆâ€å‡ºæ¥ï¼Œä½† ECS ä»»åŠ¡å’Œ Aurora æ•°æ®åº“ä¸ä¼šçœŸçš„è·‘ï¼Œåªèƒ½ä½œä¸º IaC æµ‹è¯•

è¦ä¸è¦æˆ‘å¸®ä½ åšä¸€ä¸ª ç®€åŒ–ç‰ˆæœ¬ï¼Œåªç”¨ VPC + ECSï¼ˆä¸åŠ  Auroraï¼‰ï¼Œè¿™æ ·ä½ èƒ½åœ¨ LocalStack å…è´¹ç‰ˆé‡Œè·‘é€šï¼Œå¹¶çœ‹åˆ° ECS cluster stubï¼Ÿ

ã‚ãªãŸ:
åšä¸€ä¸ªå®Œæ•´çš„pythonå·¥ç¨‹ï¼Œå®ç°ä¸Šé¢çš„å†…å®¹
ChatGPT:

æ˜ç™½äº†ï¼Œæˆ‘å¸®ä½ æ•´ç†ä¸€ä¸ª å®Œæ•´çš„ Python CDK v2 å·¥ç¨‹ç»“æ„ï¼Œå®ç° VPC + ECS (Fargate) + Aurora MySQLã€‚è¿™ä¸ªå·¥ç¨‹åœ¨ AWS çœŸç¯å¢ƒå¯ä»¥å®Œå…¨éƒ¨ç½²ï¼Œåœ¨ LocalStack å…è´¹ç‰ˆåªèƒ½æ¨¡æ‹Ÿéƒ¨åˆ†èµ„æºï¼ˆECS/Aurora ä»»åŠ¡ä¸ä¼šçœŸæ­£è¿è¡Œï¼‰ã€‚

1ï¸âƒ£ å·¥ç¨‹ç»“æ„
my_cdk_project/
â”œâ”€â”€ app.py
â”œâ”€â”€ my_stack.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ cdk.json
â””â”€â”€ README.md

2ï¸âƒ£ requirements.txt
aws-cdk-lib>=2.0.0
constructs>=10.0.0


å¦‚æœç”¨ LocalStackï¼š

aws-cdk-lib>=2.0.0
constructs>=10.0.0
aws-cdk-local


å®‰è£…ä¾èµ–ï¼š

python -m pip install -r requirements.txt

3ï¸âƒ£ cdk.json
{
  "app": "python3 app.py"
}

4ï¸âƒ£ app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from my_stack import MyInfraStack

app = cdk.App()
MyInfraStack(app, "MyInfraStack")
app.synth()

5ï¸âƒ£ my_stack.py
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # 1. åˆ›å»º VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # 2. ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # 3. Fargate Service + ALB
        ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # 4. Aurora MySQL Cluster (Serverless)
        rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

6ï¸âƒ£ éƒ¨ç½²æ­¥éª¤
âœ… AWS çœŸç¯å¢ƒ
cdk bootstrap
cdk deploy --require-approval never

âœ… LocalStackï¼ˆæ¨¡æ‹Ÿèµ„æºï¼‰
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never


ä¸Šä¼  ECS é•œåƒæˆ–è€…æµ‹è¯• S3 å¯é€šè¿‡ LocalStack endpointï¼š

aws --endpoint-url=http://localhost:4566 s3 cp ./input.zip s3://my-bucket/

7ï¸âƒ£ æ³¨æ„äº‹é¡¹

LocalStack å…è´¹ç‰ˆä¸èƒ½çœŸæ­£è¿è¡Œ ECS ä»»åŠ¡æˆ– Auroraï¼Œåªèƒ½åš IaC æµ‹è¯•ã€‚

Aurora Serverless v2 éœ€è¦çœŸå® AWS æ‰èƒ½å¯åŠ¨æ•°æ®åº“ã€‚

ECS Fargate Task éœ€è¦å…¬å¼€é•œåƒï¼ˆå¦‚ amazon/amazon-ecs-sampleï¼‰æ‰èƒ½åœ¨ AWS ä¸Šè¿è¡Œã€‚

å¯ä»¥åœ¨ LocalStack æµ‹è¯• CDK synth å’Œèµ„æºç”Ÿæˆé€»è¾‘ã€‚

æˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥åšä¸€ä¸ª é™„åŠ åŠŸèƒ½ï¼š

è‡ªåŠ¨ä¸Šä¼ æ–‡ä»¶åˆ° S3

è§¦å‘ ECS ä»»åŠ¡å¤„ç†

è¾“å‡º Aurora endpoint

è¿™æ ·å°±æ˜¯ä¸€ä¸ª å®Œæ•´å¯æ‰§è¡Œçš„â€œæœ¬åœ°/äº‘â€æ¨¡æ‹Ÿ + çœŸç¯å¢ƒéƒ¨ç½²å·¥ç¨‹ã€‚

ä½ å¸Œæœ›æˆ‘åŠ è¿™ä¸ªå—ï¼Ÿ

ã‚ãªãŸ:
å¸Œæœ›
ChatGPT:

æ˜ç™½äº†ï¼Œæˆ‘ç»™ä½ æ‰©å±•è¿™ä¸ªå·¥ç¨‹ï¼Œè®©å®ƒæ”¯æŒï¼š

ä¸Šä¼ æ–‡ä»¶åˆ° S3

è§¦å‘ ECS ä»»åŠ¡å¤„ç†ï¼ˆæ¨¡æ‹Ÿå¤„ç†ï¼‰

è¾“å‡º Aurora endpoint

ä¸‹é¢æ˜¯å®Œæ•´æ–¹æ¡ˆï¼Œä¿æŒ CDK v2 Pythonï¼Œå¯åœ¨ AWS çœŸç¯å¢ƒéƒ¨ç½²ï¼ŒLocalStack å¯æ¨¡æ‹Ÿ IaC æµç¨‹ã€‚

1ï¸âƒ£ å·¥ç¨‹ç»“æ„ï¼ˆæ›´æ–°ï¼‰
my_cdk_project/
â”œâ”€â”€ app.py
â”œâ”€â”€ my_stack.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ upload_file.py
â”œâ”€â”€ cdk.json
â””â”€â”€ README.md

2ï¸âƒ£ requirements.txtï¼ˆæ›´æ–°ï¼‰
aws-cdk-lib>=2.0.0
constructs>=10.0.0
boto3>=1.26.0
aws-cdk-local  # å¦‚æœç”¨ LocalStack


å®‰è£…ï¼š

python -m pip install -r requirements.txt

3ï¸âƒ£ my_stack.pyï¼ˆCDK æ ¸å¿ƒ + S3 + ECS + Aurora + è¾“å‡ºï¼‰
from aws_cdk import (
    Stack,
    aws_ec2 as ec2,
    aws_s3 as s3,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_rds as rds,
    CfnOutput,
)
from constructs import Construct

class MyInfraStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # 1ï¸âƒ£ VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # 2ï¸âƒ£ S3 Bucketï¼ˆä¸Šä¼ æ–‡ä»¶ç”¨ï¼‰
        source_bucket = s3.Bucket(self, "MySourceBucket")

        # 3ï¸âƒ£ ECS Cluster
        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        # 4ï¸âƒ£ Fargate Service + ALB
        fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "MyFargateService",
            cluster=cluster,
            memory_limit_mib=512,
            cpu=256,
            desired_count=1,
            public_load_balancer=True,
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")
            ),
        )

        # 5ï¸âƒ£ Aurora MySQL Cluster (Serverless)
        aurora_cluster = rds.DatabaseCluster(
            self, "MyAuroraCluster",
            engine=rds.DatabaseClusterEngine.aurora_mysql(
                version=rds.AuroraMysqlEngineVersion.VER_3_03_0
            ),
            instances=1,
            credentials=rds.Credentials.from_generated_secret("admin"),
            default_database_name="mydb",
            instance_props=rds.InstanceProps(
                vpc=vpc,
                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS),
                instance_type=ec2.InstanceType.of(
                    ec2.InstanceClass.BURSTABLE3,
                    ec2.InstanceSize.MEDIUM,
                ),
            ),
        )

        # 6ï¸âƒ£ è¾“å‡ºä¿¡æ¯
        CfnOutput(self, "S3BucketName", value=source_bucket.bucket_name)
        CfnOutput(self, "FargateURL", value=fargate_service.load_balancer.load_balancer_dns_name)
        CfnOutput(self, "AuroraEndpoint", value=aurora_cluster.cluster_endpoint.hostname)

4ï¸âƒ£ scripts/upload_file.pyï¼ˆä¸Šä¼ æ–‡ä»¶åˆ° S3 + æ¨¡æ‹Ÿè§¦å‘ ECSï¼‰
import boto3
import os

# AWS é…ç½®
AWS_REGION = "us-east-1"
S3_BUCKET = os.environ.get("S3_BUCKET", "MySourceBucket")  # å¯ä» CDK è¾“å‡ºä¼ å…¥
FILE_PATH = "input.zip"
KEY_NAME = "input.zip"

# 1ï¸âƒ£ ä¸Šä¼ æ–‡ä»¶åˆ° S3
s3_client = boto3.client("s3", region_name=AWS_REGION)
s3_client.upload_file(FILE_PATH, S3_BUCKET, KEY_NAME)
print(f"Uploaded {FILE_PATH} to s3://{S3_BUCKET}/{KEY_NAME}")

# 2ï¸âƒ£ æ¨¡æ‹Ÿè§¦å‘ ECS ä»»åŠ¡
ecs_client = boto3.client("ecs", region_name=AWS_REGION)
cluster_name = os.environ.get("ECS_CLUSTER", "MyCluster")
task_definition = os.environ.get("TASK_DEF", "MyFargateService")  # CDK ä¼šè‡ªåŠ¨åˆ›å»º

response = ecs_client.run_task(
    cluster=cluster_name,
    launchType="FARGATE",
    taskDefinition=task_definition,
    networkConfiguration={
        'awsvpcConfiguration': {
            'subnets': ['subnet-xxxxxx'],  # æ›¿æ¢æˆ CDK è¾“å‡ºçš„ç§æœ‰å­ç½‘
            'assignPublicIp': 'ENABLED'
        }
    }
)
print("ECS task triggered:", response)


âš ï¸ æ³¨æ„ï¼š

åœ¨ AWS ä¸Šï¼Œsubnets å¿…é¡»æ›¿æ¢ä¸º CDK è¾“å‡ºçš„ VPC å­ç½‘ IDã€‚

LocalStack å…è´¹ç‰ˆæ— æ³•çœŸæ­£è¿è¡Œ ECS ä»»åŠ¡ï¼Œä½†ä½ å¯ä»¥æµ‹è¯• IaC æµç¨‹å’Œ S3 ä¸Šä¼ ã€‚

5ï¸âƒ£ éƒ¨ç½² & æµ‹è¯•
AWS çœŸç¯å¢ƒï¼š
cdk bootstrap
cdk deploy --require-approval never


æŸ¥çœ‹è¾“å‡ºï¼š

aws s3 ls
# è¾“å‡º S3 bucket åç§°


ä¸Šä¼ æ–‡ä»¶å¹¶è§¦å‘ ECSï¼š

export S3_BUCKET=<CDKè¾“å‡ºçš„S3BucketName>
export ECS_CLUSTER=<CDKè¾“å‡ºçš„ClusterName>
export TASK_DEF=<CDKè¾“å‡ºçš„FargateServiceName>
python scripts/upload_file.py

LocalStack æ¨¡æ‹Ÿï¼š
pip install aws-cdk-local
cdklocal bootstrap
cdklocal deploy --require-approval never

export AWS_ACCESS_KEY_ID=test
export AWS_SECRET_ACCESS_KEY=test
export AWS_DEFAULT_REGION=us-east-1
export S3_BUCKET=MySourceBucket
python scripts/upload_file.py --endpoint-url=http://localhost:4566


LocalStack å…è´¹ç‰ˆï¼š

S3 ä¸Šä¼ ä¼šæˆåŠŸ

ECS ä»»åŠ¡å’Œ Aurora endpoint åªæ˜¯ mockï¼Œä¸ä¼šçœŸæ­£è¿è¡Œ

æˆ‘å¯ä»¥å¸®ä½ å†å†™ä¸€ä¸ª è„šæœ¬è‡ªåŠ¨è¯»å– CDK è¾“å‡ºï¼Œå¹¶åŠ¨æ€å¡«å…… ECS å­ç½‘/Task Definitionï¼Œè¿™æ · upload_file.py å¯ä»¥ ç›´æ¥æ‹¿ CDK è¾“å‡ºè¿è¡Œï¼Œä¸éœ€è¦æ‰‹åŠ¨æ›¿æ¢ã€‚

ä½ å¸Œæœ›æˆ‘åŠ å—ï¼Ÿ

